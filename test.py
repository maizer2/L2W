page = "Abstract. Image-based virtual try-on systems for fitting a new in-shop\nclothes into a person image have attracted increasing research attention,\nyet is still challenging. A desirable pipeline should not only transform the\ntarget clothes into the most fitting shape seamlessly but also preserve well\nthe clothes identity in the generated image, that is, the key characteristics\n(e.g. texture, logo, embroidery) that depict the original clothes. However,\nprevious image-conditioned generation works fail to meet these critical\nrequirements towards the plausible virtual try-on performance since they\nfail to handle large spatial misalignment between the input image and\ntarget clothes. Prior work explicitly tackled spatial deformation using\nshape context matching, but failed to preserve clothing details due to\nits coarse-to-fine strategy. In this work, we propose a new fully-learnable\nCharacteristic-Preserving Virtual Try-On Network (CP-VTON) for ad-\ndressing all real-world challenges in this task. First, CP-VTON learns\na thin-plate spline transformation for transforming the in-shop clothes\ninto fitting the body shape of the target person via a new Geometric\nMatching Module (GMM) rather than computing correspondences of in-\nterest points as prior works did. Second, to alleviate boundary artifacts of\nwarped clothes and make the results more realistic, we employ a Try-On\nModule that learns a composition mask to integrate the warped clothes\nand the rendered image to ensure smoothness. Extensive experiments\non a fashion dataset demonstrate our CP-VTON achieves the state-of-\nthe-art virtual try-on performance both qualitatively and quantitatively.\nCode is available a"

print(len(page))

for i in range(len(page)):
    if i == len(page) - 1:
        print("last")